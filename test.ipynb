{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adj:  (2708, 2708)\n",
      "features:  (2708, 1433)\n"
     ]
    }
   ],
   "source": [
    "from utils import *\n",
    "\n",
    "adj, feat, labels, idx_train, idx_val, idx_test, ano_labels = load('cora')\n",
    "print(\"adj: \", adj.shape)\n",
    "print(\"features: \", feat.shape)\n",
    "print(\"train_size:\", len(idx_train))\n",
    "print(\"val_size:\", len(idx_val))\n",
    "print(\"test_size:\", len(idx_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized adj:  (16484, 16484)\n",
      "features:  (16484, 8337)\n",
      "label:  (16484,)\n",
      "original adj:  (16484, 16484)\n",
      "Sum or anomalies:  597\n"
     ]
    }
   ],
   "source": [
    "# =============== Dominant ===============\n",
    "def load_anomaly_detection_dataset(dataset, datadir='data'):\n",
    "    data_mat = sio.loadmat(f'{datadir}/{dataset}.mat')\n",
    "    adj = data_mat['Network']\n",
    "    feat = data_mat['Attributes']\n",
    "    truth = data_mat['Label']\n",
    "    truth = truth.flatten()\n",
    "\n",
    "    adj_norm = normalize_adj(adj + sp.eye(adj.shape[0]))\n",
    "    adj_norm = adj_norm.toarray()\n",
    "    adj = adj + sp.eye(adj.shape[0])\n",
    "    adj = adj.toarray()\n",
    "    feat = feat.toarray()\n",
    "    return adj_norm, feat, truth, adj\n",
    "\n",
    "adj, attrs, label, adj_label = load_anomaly_detection_dataset('ACM')\n",
    "print(\"normalized adj: \", adj.shape)\n",
    "print(\"features: \", attrs.shape)\n",
    "print(\"label: \", label.shape)\n",
    "print(\"original adj: \", adj_label.shape)\n",
    "print(\"Sum or anomalies: \", sum(label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MAE: random_masking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.4242, 0.2900],\n",
       "         [0.3482, 0.5577],\n",
       "         [0.2255, 0.1098],\n",
       "         [0.8989, 0.5212],\n",
       "         [0.7968, 0.0127]],\n",
       "\n",
       "        [[0.3815, 0.1038],\n",
       "         [0.2913, 0.9885],\n",
       "         [0.6024, 0.2209],\n",
       "         [0.1044, 0.9607],\n",
       "         [0.6929, 0.2405]],\n",
       "\n",
       "        [[0.1717, 0.6199],\n",
       "         [0.4443, 0.0392],\n",
       "         [0.0725, 0.5095],\n",
       "         [0.2704, 0.8845],\n",
       "         [0.1892, 0.1595]],\n",
       "\n",
       "        [[0.6444, 0.4932],\n",
       "         [0.7901, 0.1293],\n",
       "         [0.1907, 0.7914],\n",
       "         [0.7692, 0.4905],\n",
       "         [0.1445, 0.6353]]])"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.rand((4, 5, 2))\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0835, 0.5561, 0.9291, 0.7978, 0.9702],\n",
       "        [0.5953, 0.2089, 0.5204, 0.3862, 0.4703],\n",
       "        [0.1807, 0.2943, 0.8598, 0.4118, 0.7235],\n",
       "        [0.1801, 0.3224, 0.7655, 0.5698, 0.9442]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noise = torch.rand(4, 5)\n",
    "noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1, 3, 2, 4],\n",
       "        [1, 3, 4, 2, 0],\n",
       "        [0, 1, 3, 4, 2],\n",
       "        [0, 1, 3, 2, 4]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids_shuffle = torch.argsort(noise, dim=1)  # ascend: small is keep, large is remove\n",
    "ids_shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1, 3, 2, 4],\n",
       "        [4, 0, 3, 1, 2],\n",
       "        [0, 1, 4, 2, 3],\n",
       "        [0, 1, 3, 2, 4]])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids_restore = torch.argsort(ids_shuffle, dim=1)\n",
    "ids_restore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1, 3],\n",
       "        [1, 3, 4],\n",
       "        [0, 1, 3],\n",
       "        [0, 1, 3]])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids_keep = ids_shuffle[:, :3]\n",
    "ids_keep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.0841, 0.7777],\n",
       "         [0.2600, 0.6878],\n",
       "         [0.5623, 0.3064]],\n",
       "\n",
       "        [[0.5746, 0.9682],\n",
       "         [0.3447, 0.8661],\n",
       "         [0.1676, 0.4896]],\n",
       "\n",
       "        [[0.4387, 0.9735],\n",
       "         [0.8970, 0.7504],\n",
       "         [0.7708, 0.4949]],\n",
       "\n",
       "        [[0.0260, 0.9256],\n",
       "         [0.9354, 0.9779],\n",
       "         [0.6392, 0.9462]]])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_masked = torch.gather(x, dim=1, index=ids_keep.unsqueeze(-1).repeat(1, 1, 2))\n",
    "x_masked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 1., 0., 1.],\n",
       "        [1., 0., 1., 0., 0.],\n",
       "        [0., 0., 1., 0., 1.],\n",
       "        [0., 0., 1., 0., 1.]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = torch.ones([4, 5], device=x.device)\n",
    "mask[:, :3] = 0\n",
    "# unshuffle to get the binary mask\n",
    "mask = torch.gather(mask, dim=1, index=ids_restore)\n",
    "mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Debug:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<function moco_graph_encoder at 0x7f81808a4790>\n"
     ]
    }
   ],
   "source": [
    "import moco as moco\n",
    "\n",
    "print(moco.__dict__['moco_graph_encoder'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0808, 0.9130],\n",
      "        [0.8778, 0.8021],\n",
      "        [0.0944, 0.6027],\n",
      "        [0.2141, 0.1238]])\n",
      "tensor([[0.8555, 0.2620],\n",
      "        [0.9656, 0.1462],\n",
      "        [0.1758, 0.5150],\n",
      "        [0.4018, 0.3649]])\n"
     ]
    }
   ],
   "source": [
    "h_pl = torch.rand((4, 2))\n",
    "c = torch.rand((4, 2))\n",
    "print(h_pl)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[ 0.3055],\n",
       "         [ 0.4926],\n",
       "         [-0.1603],\n",
       "         [-0.1570]], grad_fn=<AddBackward0>)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "n_h = 2\n",
    "f_k = nn.Bilinear(n_h, n_h, 1)\n",
    "\n",
    "scs = []\n",
    "scs.append(f_k(h_pl, c))\n",
    "scs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1758, 0.5150],\n",
      "        [0.8555, 0.2620],\n",
      "        [0.9656, 0.1462],\n",
      "        [0.1758, 0.5150]])\n"
     ]
    }
   ],
   "source": [
    "c_mi = c\n",
    "negsamp_round = 1\n",
    "for _ in range(negsamp_round):\n",
    "    c_mi = torch.cat((c_mi[-2:-1,:], c_mi[:-1,:]),0)\n",
    "    print(c_mi)\n",
    "    scs.append(f_k(h_pl, c_mi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[ 0.3055],\n",
      "        [ 0.4926],\n",
      "        [-0.1603],\n",
      "        [-0.1570]], grad_fn=<AddBackward0>), tensor([[-0.1441],\n",
      "        [ 0.3266],\n",
      "        [ 0.2137],\n",
      "        [-0.2137]], grad_fn=<AddBackward0>)]\n"
     ]
    }
   ],
   "source": [
    "print(scs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.3055],\n",
       "        [ 0.4926],\n",
       "        [-0.1603],\n",
       "        [-0.1570],\n",
       "        [-0.1441],\n",
       "        [ 0.3266],\n",
       "        [ 0.2137],\n",
       "        [-0.2137]], grad_fn=<CatBackward0>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits = torch.cat(tuple(scs))\n",
    "logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.2789, 0.2368],\n",
       "         [0.8589, 0.8995],\n",
       "         [0.1355, 0.6173],\n",
       "         [0.6932, 0.8482],\n",
       "         [0.6499, 0.5748]],\n",
       "\n",
       "        [[0.4149, 0.4989],\n",
       "         [0.7000, 0.2095],\n",
       "         [0.5814, 0.5955],\n",
       "         [0.2664, 0.6382],\n",
       "         [0.3337, 0.7935]],\n",
       "\n",
       "        [[0.2979, 0.6018],\n",
       "         [0.3499, 0.3546],\n",
       "         [0.2195, 0.0341],\n",
       "         [0.2673, 0.9819],\n",
       "         [0.3262, 0.5714]],\n",
       "\n",
       "        [[0.9486, 0.0165],\n",
       "         [0.0677, 0.1777],\n",
       "         [0.0727, 0.1079],\n",
       "         [0.3486, 0.1212],\n",
       "         [0.0447, 0.4711]]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.rand((4, 5, 2))\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2789, 0.2368],\n",
       "        [0.4149, 0.4989],\n",
       "        [0.2979, 0.6018],\n",
       "        [0.9486, 0.0165]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[:, 0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1433])\n"
     ]
    }
   ],
   "source": [
    "from dgl.nn.pytorch.glob import AvgPooling\n",
    "\n",
    "avg = AvgPooling()\n",
    "\n",
    "out = avg(temp, temp.ndata[\"features\"])\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = out.to(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 32])\n"
     ]
    }
   ],
   "source": [
    "drop = nn.Dropout(0.2)\n",
    "linear = nn.Linear(1433, 32)\n",
    "out = drop(linear(out))\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_over_layer = 0\n",
    "score_over_layer += out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 32])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_over_layer.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.4061, -0.9381],\n",
      "        [-0.6663,  0.9505],\n",
      "        [ 0.6383,  1.0689],\n",
      "        [ 1.8522, -0.2765]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Sinkhorn-Knopp\n",
    "def sinkhorn(scores, eps=0.05, niters=3):\n",
    "    Q = torch.exp(scores / eps).T\n",
    "    Q /= sum(Q)\n",
    "    K, B = Q.shape\n",
    "    u, r, c = torch.zeros(K), torch.ones(K) / K, torch.ones(B) / B\n",
    "    for _ in range(niters):\n",
    "        u = torch.sum(Q, dim=1)\n",
    "        Q *= (r / u).unsqueeze(1)\n",
    "        Q *= (c / torch.sum(Q, dim=0)).unsqueeze(0)\n",
    "    return (Q / torch.sum(Q, dim=0, keepdim=True)).T\n",
    "\n",
    "z = torch.randn((4, 2))\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[9.9998e-01, 2.3970e-05],\n",
       "        [9.0603e-15, 1.0000e+00],\n",
       "        [1.8182e-04, 9.9982e-01],\n",
       "        [1.0000e+00, 3.2391e-19]])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = sinkhorn(z)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.8667, 0.7765, 0.2961, 0.1600]])\n",
      "tensor([[0.3365, 0.3074, 0.1902, 0.1660]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.rand((1, 4))\n",
    "print(a)\n",
    "b = F.softmax(a, dim=1)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2.9739, 2.7173, 1.6808, 1.4670]])\n"
     ]
    }
   ],
   "source": [
    "T = 0.8\n",
    "numerator = np.exp(a) / T\n",
    "print(numerator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MCL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([8., 2., 2., 7.])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "y = torch.randint(0, 10, (4, ), dtype=torch.float32)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 4])\n"
     ]
    }
   ],
   "source": [
    "c = [y] * len(y)\n",
    "mask = torch.stack(c)\n",
    "print(mask.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[8., 2., 2., 7.],\n",
      "        [8., 2., 2., 7.],\n",
      "        [8., 2., 2., 7.],\n",
      "        [8., 2., 2., 7.]])\n"
     ]
    }
   ],
   "source": [
    "print(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1., -6., -6., -1.],\n",
      "        [ 6., -1.,  0.,  5.],\n",
      "        [ 6.,  0., -1.,  5.],\n",
      "        [ 1., -5., -5., -1.]])\n",
      "tensor([[0, 0, 0, 0],\n",
      "        [0, 0, 1, 0],\n",
      "        [0, 1, 0, 0],\n",
      "        [0, 0, 0, 0]], dtype=torch.uint8)\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(mask)):\n",
    "    mask[i] = mask[i]- mask[i][i]\n",
    "    mask[i][i] -= 1\n",
    "print(mask)\n",
    "same_class_mask = (mask == 0).type(torch.uint8)\n",
    "print(same_class_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0])"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_choice = torch.nonzero(torch.tensor([0, 1, 1, 1])).squeeze()\n",
    "random_idx = torch.randint(random_choice.size()[0], (1,))\n",
    "random_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2, 8, 6, 2])\n",
      "tensor([ 4, 16, 12,  4])\n",
      "tensor([[ 4,  4],\n",
      "        [16, 16],\n",
      "        [12, 12],\n",
      "        [ 4,  4]])\n",
      "tensor([ 4,  4, 16, 16, 12, 12,  4,  4])\n",
      "tensor([ 4,  5, 16, 17, 12, 13,  4,  5])\n"
     ]
    }
   ],
   "source": [
    "label = torch.randint(0, 10, (4, ))\n",
    "print(label)\n",
    "label = label * 2\n",
    "print(label)\n",
    "label_copy1 = torch.unsqueeze(label, 1)\n",
    "label_copy2 = torch.unsqueeze(label, 1)\n",
    "concatted = torch.cat([label_copy1, label_copy2], 1)\n",
    "print(concatted)\n",
    "result = concatted.view([-1, 4*2]).squeeze()\n",
    "print(result)\n",
    "result[1::2]+=1\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.5663,  0.5757, -0.3176, -0.8358],\n",
      "        [-0.2623,  0.6032,  1.3866,  0.5395],\n",
      "        [ 0.1110, -1.1922, -1.3357,  0.4411],\n",
      "        [ 0.4062, -1.6155,  0.3412, -1.2924]])\n",
      "tensor([[ 0.5757, -0.3176, -0.8358],\n",
      "        [-0.2623,  1.3866,  0.5395],\n",
      "        [ 0.1110, -1.1922,  0.4411],\n",
      "        [ 0.4062, -1.6155,  0.3412]])\n"
     ]
    }
   ],
   "source": [
    "bs = 2\n",
    "sim_matrix = torch.randn((2*bs, 2*bs))\n",
    "print(sim_matrix)\n",
    "# mask diag\n",
    "mask = (torch.ones_like(sim_matrix) - torch.eye(2 * bs, device=sim_matrix.device)).bool()\n",
    "sim_matrix = sim_matrix.masked_select(mask).view(2 * bs, -1)\n",
    "print(sim_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([0.4656903 , 0.54330534, 0.69853544, 0.        ], dtype=float32), array([0.3810004 , 0.        , 0.25400025, 0.8890009 ], dtype=float32), array([0.22222222, 0.5555556 , 0.6666667 , 0.44444445], dtype=float32), array([0.6620847 , 0.08276059, 0.        , 0.7448453 ], dtype=float32)]\n",
      "[[ 0.03355981 -0.02669422 -0.04349511  0.01041558]\n",
      " [-0.02669422  0.08720489  0.09052245 -0.1017936 ]\n",
      " [-0.04349511  0.09052245  0.11381943 -0.10639684]\n",
      " [ 0.01041558 -0.1017936  -0.10639684  0.15427499]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "reps = []\n",
    "for i in range(4):\n",
    "    p = torch.randint(0, 10, (1, 4), dtype=torch.float32)\n",
    "    p = F.normalize(p, dim=1)\n",
    "    p = p.numpy()\n",
    "    reps.append(p.squeeze())\n",
    "print(reps)\n",
    "cov = np.cov(reps, rowvar= False)\n",
    "print(cov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "for i in range(4):\n",
    "    x = int((i-1)/2)\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 1, 2, 3, 4, 5, 6, 7])\n",
      "tensor([1, 1, 3, 3, 5, 5, 7, 7])\n",
      "tensor([1, 0, 3, 2, 5, 4, 7, 6])\n"
     ]
    }
   ],
   "source": [
    "targets = torch.arange(8)\n",
    "print(targets)\n",
    "targets[::2] += 1\n",
    "print(targets)\n",
    "targets[1::2] -= 1\n",
    "print(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[3., 3., 3., 3., 5., 5., 6., 6.],\n",
       "          [3., 3., 3., 3., 5., 5., 6., 6.],\n",
       "          [2., 2., 4., 4., 5., 5., 6., 6.],\n",
       "          [2., 2., 4., 4., 5., 5., 6., 6.],\n",
       "          [2., 2., 3., 3., 6., 6., 6., 6.],\n",
       "          [2., 2., 3., 3., 6., 6., 6., 6.],\n",
       "          [2., 2., 3., 3., 5., 5., 7., 7.],\n",
       "          [2., 2., 3., 3., 5., 5., 7., 7.]]]])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "diag = torch.eye(len(y))\n",
    "mask += diag\n",
    "mask_sum = mask.view(1,1,len(y),len(y))\n",
    "mask_final = F.interpolate(mask_sum,scale_factor = 2,mode='nearest')\n",
    "mask_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.]]])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_pos = (mask>0).type(torch.float)\n",
    "mask_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 0., 1.]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diag = torch.eye(len(y))\n",
    "diag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 1, 2, 3])\n",
      "tensor([1, 1, 3, 3])\n",
      "tensor([1, 0, 3, 2])\n"
     ]
    }
   ],
   "source": [
    "# targets 2N elements.\n",
    "targets = torch.arange(4)\n",
    "print(targets)\n",
    "targets[::2] += 1\n",
    "print(targets) \n",
    "targets[1::2] -= 1\n",
    "print(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to data/cifar10/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 170498071/170498071 [00:59<00:00, 2853146.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/cifar10/cifar-10-python.tar.gz to data/cifar10\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import torchvision\n",
    "\n",
    "d_train = torchvision.datasets.CIFAR10('data/cifar10', train=True, transform=None, target_transform=None, download=True)\n",
    "d_test = torchvision.datasets.CIFAR10('data/cifar10', train=False, transform=None, target_transform=None, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './tmp/cifar10/train_combined.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [28]\u001b[0m, in \u001b[0;36m<cell line: 13>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m     l \u001b[38;5;241m=\u001b[39m [img,\u001b[38;5;28mint\u001b[39m(target)]\n\u001b[1;32m     11\u001b[0m     p_test\u001b[38;5;241m.\u001b[39mappend(l)\n\u001b[0;32m---> 13\u001b[0m p\u001b[38;5;241m.\u001b[39mdump(p_train,\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./tmp/cifar10/train_combined.pkl\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mwb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     14\u001b[0m p\u001b[38;5;241m.\u001b[39mdump(p_test,\u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./tmp/cifar10/test_combined.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './tmp/cifar10/train_combined.pkl'"
     ]
    }
   ],
   "source": [
    "import pickle as p\n",
    "\n",
    "p_train, p_test = [], []\n",
    "\n",
    "for img,target in zip(d_train.data,d_train.targets):\n",
    "    l = [img,int(target)]\n",
    "    p_train.append(l)\n",
    "\n",
    "for img,target in zip(d_test.data, d_test.targets):\n",
    "    l = [img,int(target)]\n",
    "    p_test.append(l)\n",
    "\n",
    "p.dump(p_train,open('./tmp/cifar10/train_combined.pkl','wb'))\n",
    "p.dump(p_test,open('./tmp/cifar10/test_combined.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2, 1],\n",
      "        [2, 2],\n",
      "        [2, 3],\n",
      "        [3, 0]])\n",
      "[[ 0.25       -0.5       ]\n",
      " [-0.5         1.66666667]]\n"
     ]
    }
   ],
   "source": [
    "x = torch.randint(0, 4, (4, 2)) # (N, C)\n",
    "print(x)\n",
    "cov = np.cov(x, rowvar= False) # (N, N)\n",
    "print(cov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.2132, -0.2886],\n",
      "        [ 2.0017, -0.8415],\n",
      "        [ 0.1093,  1.2570],\n",
      "        [ 0.7835,  1.8634]])\n",
      "tensor([0, 0, 1, 1])\n",
      "torch.Size([4, 2, 1])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn((4, 2)) # (B, C)\n",
    "print(x)\n",
    "print(x.max(1)[1])\n",
    "x = x.view(x.size(0), x.size(1), -1)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mahalanobis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num of layers:  5\n",
      "size of each layer:  torch.Size([32, 64, 32, 32])\n",
      "size of each layer:  torch.Size([32, 64, 32, 32])\n",
      "size of each layer:  torch.Size([32, 128, 16, 16])\n",
      "size of each layer:  torch.Size([32, 256, 8, 8])\n",
      "size of each layer:  torch.Size([32, 512, 4, 4])\n",
      "feature_list: [ 64.  64. 128. 256. 512.]\n"
     ]
    }
   ],
   "source": [
    "# load networks\n",
    "from resnet import ResNet34\n",
    "model = ResNet34(num_c=10)\n",
    "\n",
    "# set information about feature extaction\n",
    "model.eval()\n",
    "temp_x = torch.rand(32, 3, 32, 32)\n",
    "temp_x = temp_x.detach()\n",
    "temp_list = model.feature_list(temp_x)[1] # (B, C, H, W)\n",
    "num_output = len(temp_list)\n",
    "print(\"num of layers: \", num_output)\n",
    "for i in range(len(temp_list)):\n",
    "    print(\"size of each layer: \", temp_list[i].shape)\n",
    "\n",
    "feature_list = np.empty(num_output) # [0] * num_layers\n",
    "count = 0\n",
    "for out in temp_list:\n",
    "    feature_list[count] = out.size(1) # C\n",
    "    count += 1\n",
    "print(\"feature_list:\", feature_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 64])\n",
      "torch.Size([32, 64])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 256])\n",
      "torch.Size([32, 512])\n"
     ]
    }
   ],
   "source": [
    "out_features = temp_list\n",
    "for i in range(num_output):\n",
    "    out_features[i] = out_features[i].view(out_features[i].size(0), out_features[i].size(1), -1) # (B, C, H*W)\n",
    "    out_features[i] = torch.mean(out_features[i].data, 2) # (B, C)\n",
    "    print(out_features[i].data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 10\n",
    "num_sample_per_class = np.empty(num_classes) # [0] * 10\n",
    "num_sample_per_class.fill(0)\n",
    "list_features = []\n",
    "for i in range(num_output):\n",
    "    temp_list = [] # [0] * 10\n",
    "    for j in range(num_classes):\n",
    "        temp_list.append(0)\n",
    "    list_features.append(temp_list) # [[0] * 10] * num_layers\n",
    "\n",
    "target = torch.randint(0, 10, (32, ))\n",
    "data = temp_x\n",
    "\n",
    "# construct the sample matrix\n",
    "for i in range(data.size(0)): # [0, B-1]\n",
    "    label = target[i]\n",
    "    if num_sample_per_class[label] == 0:\n",
    "        out_count = 0\n",
    "        for out in out_features: # out: (B, num_feature)\n",
    "            list_features[out_count][label] = out[i].view(1, -1) # (1, num_feature)\n",
    "            out_count += 1\n",
    "    else:\n",
    "        out_count = 0\n",
    "        for out in out_features:\n",
    "            list_features[out_count][label] \\\n",
    "            = torch.cat((list_features[out_count][label], out[i].view(1, -1)), 0)\n",
    "            out_count += 1                \n",
    "    num_sample_per_class[label] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "10\n",
      "32\n",
      "64\n"
     ]
    }
   ],
   "source": [
    "# (num_layers, num_class, N_c, C)\n",
    "print(len(list_features))\n",
    "print(len(list_features[0]))\n",
    "tmp = 0\n",
    "for i in range(num_classes):\n",
    "    tmp += len(list_features[0][i])\n",
    "print(tmp)\n",
    "print(len(list_features[0][0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "torch.Size([10, 64])\n"
     ]
    }
   ],
   "source": [
    "sample_class_mean = [] # [(num_classes, C)] * num_layers\n",
    "out_count = 0\n",
    "for num_feature in feature_list: # num_layers\n",
    "    temp_list = torch.Tensor(num_classes, int(num_feature)) # (num_classes, C)\n",
    "    for j in range(num_classes):\n",
    "        temp_list[j] = torch.mean(list_features[out_count][j], 0) # (N_c, C) -> (1, C)\n",
    "    sample_class_mean.append(temp_list)\n",
    "    out_count += 1\n",
    "print(len(sample_class_mean))\n",
    "print(sample_class_mean[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "torch.Size([64, 64])\n"
     ]
    }
   ],
   "source": [
    "import sklearn.covariance\n",
    "\n",
    "group_lasso = sklearn.covariance.EmpiricalCovariance(assume_centered=False)\n",
    "\n",
    "precision = []\n",
    "for k in range(num_output):\n",
    "    X = 0\n",
    "    for i in range(num_classes):\n",
    "        if i == 0:\n",
    "            X = list_features[k][i] - sample_class_mean[k][i] # (N_c, C)\n",
    "        else:\n",
    "            X = torch.cat((X, list_features[k][i] - sample_class_mean[k][i]), 0) # (N, C)\n",
    "    # find inverse            \n",
    "    group_lasso.fit(X.numpy())\n",
    "    temp_precision = group_lasso.precision_\n",
    "    temp_precision = torch.from_numpy(temp_precision).float() # (C, N)\n",
    "    precision.append(temp_precision) # [(C, N)] * num_layers\n",
    "print(len(precision))\n",
    "print(precision[0].shape) # [(C, C)] * num_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.4317,  0.1070],\n",
      "        [-0.3850, -0.6187],\n",
      "        [ 0.4838,  0.0031]])\n",
      "tensor([[-2.2033,  2.2806],\n",
      "        [ 0.0719,  1.6152]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn((3, 2)) # (B, C)\n",
    "sigma = torch.randn((2, 2)) # (C, C)\n",
    "print(x)\n",
    "print(sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 1])\n"
     ]
    }
   ],
   "source": [
    "y = torch.mm(torch.mm(x, sigma), x.t()).diag()\n",
    "y = y.view(-1, 1)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.2834,  0.0621],\n",
      "        [ 0.8519, -0.5122],\n",
      "        [-0.5122,  0.8572]])\n",
      "torch.Size([3, 2])\n"
     ]
    }
   ],
   "source": [
    "t = torch.randn((3, 1))\n",
    "t = torch.cat((y, t), 1)\n",
    "print(t)\n",
    "print(t.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.max(\n",
       "values=tensor([0.0621, 0.8519, 0.8572]),\n",
       "indices=tensor([1, 0, 1]))"
      ]
     },
     "execution_count": 361,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.max(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([ 0.1002, -1.0799,  0.3467,  0.8103])"
      ]
     },
     "execution_count": 374,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn((4, 2))\n",
    "y = torch.randn((4, 2))\n",
    "z = torch.sum(x * y, dim=1)\n",
    "print(z.shape)\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1002)\n",
      "tensor(-1.0799)\n",
      "tensor(0.3467)\n",
      "tensor(0.8103)\n"
     ]
    }
   ],
   "source": [
    "for i in range(4):\n",
    "    print(sum(x[i]*y[i]))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0443)"
      ]
     },
     "execution_count": 377,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mean(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.1411],\n",
       "        [ 1.1586],\n",
       "        [-0.7949],\n",
       "        [ 1.0995]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "x = torch.randn((4, 1))\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.zeros(10, dtype=torch.long)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = [0, 1, 2, 4, 6]\n",
    "p = x[index]\n",
    "p.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.linspace(0, x.size(0)-1, steps=x.size(0)).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = torch.zeros(4, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([9])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = torch.cat([p, r],dim=0)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.zeros(500)\n",
    "t[y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 8\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from typing import List\n",
    "\n",
    "def minimumSwap(s1: str, s2: str) -> int:\n",
    "    ans = 0\n",
    "    c1 = Counter(s1)\n",
    "    c2 = Counter(s2)\n",
    "\n",
    "    x = c1[\"x\"]+c2[\"x\"]\n",
    "    y = c1[\"y\"]+c2[\"y\"]\n",
    "    print(x, y)\n",
    "    if x % 2 != 0 or y % 2 != 0:\n",
    "        return -1\n",
    "\n",
    "    tmp = []\n",
    "    n = len(s1)\n",
    "    for i in range(n):\n",
    "        if s1[i] != s2[i]:\n",
    "            tmp.append(s1[i])\n",
    "    \n",
    "    for j in range(len(tmp)-1):\n",
    "        if tmp[j] == tmp[j+1]:\n",
    "            ans += 1\n",
    "        else:\n",
    "            ans += 2\n",
    "    return ans\n",
    "\n",
    "s1 = \"xxyyxyxyxx\"\n",
    "s2 = \"xyyxyxxxyx\"\n",
    "minimumSwap(s1, s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
